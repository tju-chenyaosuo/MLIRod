all covered operations: llvm.load,bufferization.clone,pdl_interp.finalize,llvm.shl,spirv.GL.Ceil,llvm.mlir.constant,llvm.and,scf.reduce.return,llvm.intr.umax,llvm.insertvalue,spirv.GL.Pow,llvm.icmp,math.copysign,spirv.CL.u_min,memref.collapse_shape,vector.constant_mask,spirv.LogicalOr,memref.copy,spirv.GL.SAbs,cf.assert,llvm.extractvalue,async.coro.suspend,llvm.intr.log10,index.bool.constant,math.rsqrt,math.ctpop,spirv.GL.Tanh,tensor.extract,llvm.intr.masked.load,affine.dma_start,arith.mulf,spirv.FOrdLessThanEqual,vector.load,memref.global,arith.subi,llvm.mlir.undef,llvm.intr.umin,affine.vector_store,llvm.intr.ceil,spirv.FUnordEqual,spirv.CL.rint,llvm.intr.log,arith.shrui,llvm.intr.memcpy,llvm.intr.vector.reduce.add,index.shl,arith.divui,llvm.urem,llvm.extractelement,spirv.ULessThanEqual,vector.scan,vector.contract,scf.execute_region,math.absf,memref.dma_start,index.sizeof,math.log,async.runtime.is_error,omp.wsloop,omp.terminator,math.sqrt,math.log10,tensor.yield,math.cos,spirv.FUnordGreaterThan,spirv.GL.FMin,builtin.module,math.atan2,spirv.CL.floor,arith.floordivsi,async.coro.free,math.cttz,affine.if,affine.min,index.casts,vector.splat,linalg.map,index.mul,memref.extract_strided_metadata,tensor.generate,llvm.srem,spirv.Not,spirv.FUnordGreaterThanEqual,llvm.intr.exp,spirv.GL.FMix,arith.extsi,memref.rank,cf.switch,scf.while,spirv.CL.fmin,arith.minsi,spirv.GL.Ldexp,spirv.BitReverse,memref.store,llvm.sext,vector.extract,llvm.lshr,tensor.insert,llvm.store,spirv.CL.s_abs,vector.extractelement,memref.alloc,spirv.LogicalEqual,vector.shuffle,arith.cmpf,memref.dim,spirv.BitwiseXor,llvm.intr.ctlz,vector.print,spirv.BitCount,index.shru,llvm.frem,vector.create_mask,llvm.intr.pow,llvm.ashr,memref.tensor_store,scf.parallel,spirv.GL.Exp,arith.negf,spirv.CL.s_max,llvm.intr.stackrestore,llvm.sub,memref.dma_wait,math.exp,llvm.mlir.zero,affine.store,memref.alloca_scope.return,spirv.BitwiseAnd,spirv.CL.round,vector.store,spirv.BitFieldInsert,scf.condition,linalg.index,llvm.fmul,llvm.getelementptr,memref.assume_alignment,memref.atomic_rmw,spirv.CL.rsqrt,vector.insert,llvm.udiv,memref.realloc,spirv.GL.Sqrt,llvm.intr.roundeven,func.return,omp.yield,spirv.GL.Log,spirv.GL.FAbs,arith.shrsi,index.maxs,spirv.FUnordLessThan,llvm.intr.cos,arith.xori,llvm.mul,spirv.CL.erf,spirv.GL.Tan,spirv.GL.Sinh,spirv.CL.fmax,llvm.intr.masked.compressstore,memref.get_global,spirv.GL.FMax,spirv.Constant,linalg.transpose,spirv.FOrdLessThan,llvm.select,spirv.ULessThan,arith.extui,vector.flat_transpose,func.call,index.ceildivs,llvm.intr.matrix.transpose,llvm.switch,affine.load,bufferization.to_tensor,llvm.intr.smax,spirv.LogicalAnd,llvm.shufflevector,async.coro.id,llvm.bitcast,pdl_interp.func,llvm.alloca,llvm.intr.copysign,index.and,tensor.collapse_shape,linalg.dot,spirv.CL.fma,llvm.intr.fmuladd,index.divs,llvm.intr.exp2,omp.parallel,cf.br,llvm.call,tensor.dim,async.await_all,spirv.BitFieldSExtract,scf.yield,tensor.rank,affine.vector_load,llvm.xor,index.sub,memref.alloca_scope,async.runtime.create_group,index.floordivs,index.maxu,func.func,index.xor,async.coro.save,spirv.FUnordLessThanEqual,index.constant,spirv.GL.UMax,arith.ceildivsi,spirv.GL.RoundEven,spirv.SGreaterThanEqual,math.tanh,vector.broadcast,llvm.intr.vector.reduce.smin,vector.yield,llvm.zext,vector.transfer_write,spirv.CL.cos,tensor.expand_shape,memref.dealloc,spirv.FOrdGreaterThan,arith.remsi,linalg.matmul,spirv.SLessThanEqual,async.yield,llvm.intr.smin,memref.reinterpret_cast,scf.if,llvm.fcmp,spirv.LogicalNot,spirv.CL.log,llvm.intr.powi,llvm.intr.vector.reduce.and,tensor.from_elements,async.coro.end,spirv.FNegate,spirv.GL.Round,math.log1p,linalg.yield,async.add_to_group,arith.addf,spirv.CL.fabs,vector.insertelement,math.floor,spirv.LogicalNotEqual,arith.index_cast,spirv.GL.FClamp,llvm.trunc,spirv.GL.SMin,spirv.UGreaterThanEqual,arith.divf,affine.dma_wait,spirv.CL.sqrt,math.fma,llvm.intr.vector.reduce.xor,linalg.broadcast,vector.transfer_read,shape.shape_of,llvm.intr.masked.scatter,llvm.func,math.powf,llvm.fdiv,spirv.CL.tanh,index.castu,math.atan,vector.maskedload,spirv.GL.Asin,llvm.intr.assume,async.coro.begin,spirv.GL.Floor,scf.index_switch,spirv.SGreaterThan,spirv.GL.Fma,llvm.intr.vector.reduce.fmin,index.or,cf.cond_br,llvm.intr.round,vector.matrix_multiply,llvm.intr.vector.reduce.fadd,arith.divsi,arith.select,llvm.cond_br,tensor.unpack,async.runtime.await,math.exp2,async.runtime.add_to_group,arith.maxsi,llvm.intr.fabs,memref.expand_shape,spirv.CL.u_max,spirv.UGreaterThan,index.ceildivu,arith.constant,llvm.sdiv,spirv.GL.Sin,memref.cast,affine.parallel,llvm.return,index.add,affine.for,llvm.fneg,math.ceil,builtin.unrealized_conversion_cast,llvm.intr.fma,async.runtime.set_available,llvm.intr.matrix.multiply,llvm.add,spirv.FOrdNotEqual,scf.reduce,vector.reduction,math.round,arith.remf,arith.addi,bufferization.to_memref,spirv.IsNan,llvm.inttoptr,vector.compressstore,vector.multi_reduction,async.create_group,llvm.intr.ctpop,vector.gather,spirv.CL.sin,spirv.CL.exp,spirv.FUnordNotEqual,arith.minui,math.roundeven,llvm.or,llvm.br,spirv.GL.FSign,arith.cmpi,vector.transpose,spirv.GL.SClamp,vector.fma,llvm.insertelement,spirv.GL.InverseSqrt,spirv.GL.Acos,bufferization.dealloc_tensor,math.expm1,arith.shli,llvm.fsub,spirv.CL.s_min,vector.mask,tensor.cast,math.absi,arith.andi,llvm.intr.log2,tensor.empty,shape.get_extent,arith.muli,scf.for,math.fpowi,spirv.GL.SMax,llvm.intr.cttz,math.ipowi,math.tan,memref.load,index.shrs,spirv.CL.ceil,spirv.FOrdGreaterThanEqual,llvm.intr.floor,spirv.BitFieldUExtract,llvm.atomicrmw,spirv.CL.pow,spirv.FOrdEqual,spirv.INotEqual,vector.scatter,spirv.IEqual,spirv.GL.UClamp,spirv.GL.Cos,llvm.intr.vector.reduce.smax,vector.bitcast,vector.extract_strided_slice,llvm.intr.sqrt,index.divu,math.log2,bufferization.alloc_tensor,arith.ori,linalg.generic,async.runtime.create,spirv.Unordered,llvm.fadd,async.runtime.resume,llvm.ptrtoint,affine.yield,spirv.BitwiseOr,spirv.GL.Atan,spirv.IsInf,vector.warp_execute_on_lane_0,llvm.intr.stacksave,math.ctlz,spirv.GL.SSign,llvm.intr.masked.gather,spirv.GL.Cosh,llvm.intr.abs,vector.outerproduct,tensor.splat,async.execute,affine.apply,affine.max,spirv.SLessThan,arith.remui,memref.alloca,linalg.copy
all covered dialect: spirv,bufferization,affine,builtin,tensor,math,index,pdl_interp,linalg,omp,async,scf,memref,arith,vector,func,shape,llvm,cf
the number of operations: 404
the number of dialects: 19
