all covered operations: spirv.GL.SMin,linalg.dot,tensor.collapse_shape,arith.remui,tensor.extract,llvm.lshr,shape.shape_of,math.tanh,spirv.FUnordNotEqual,async.coro.end,vector.gather,spirv.Select,llvm.intr.masked.scatter,memref.store,index.mul,spirv.FUnordEqual,spirv.CL.rint,llvm.mlir.undef,arith.addf,shape.get_extent,cf.switch,cf.assert,memref.alloca_scope,arith.remf,llvm.zext,spirv.CL.sqrt,async.runtime.create_group,memref.dim,arith.negf,async.coro.id,async.execute,spirv.IMul,arith.constant,spirv.LogicalOr,spirv.GL.Asin,spirv.UGreaterThanEqual,spirv.GL.Tanh,spirv.SLessThanEqual,math.fpowi,index.sub,spirv.CL.cos,spirv.CL.s_min,spirv.GL.Acos,spirv.FUnordGreaterThan,spirv.GL.Atan,llvm.intr.roundeven,linalg.yield,cf.cond_br,bufferization.to_tensor,vector.constant_mask,vector.broadcast,affine.dma_start,spirv.GL.UClamp,llvm.load,arith.shrsi,func.call,tensor.empty,spirv.CL.log,bufferization.dealloc_tensor,memref.alloc,spirv.GL.Cos,spirv.SLessThan,scf.reduce,spirv.Unordered,math.powf,llvm.intr.vector.reduce.umin,affine.min,spirv.GL.Fma,vector.store,spirv.CL.exp,memref.rank,llvm.getelementptr,spirv.FUnordLessThanEqual,llvm.insertelement,spirv.CL.erf,arith.andi,math.absf,vector.flat_transpose,llvm.br,spirv.GL.Tan,memref.reinterpret_cast,llvm.return,spirv.IsNan,spirv.GL.Log,vector.contract,spirv.IAdd,index.ceildivu,llvm.fsub,index.divu,llvm.mul,spirv.CL.u_min,math.log10,llvm.select,arith.ori,arith.truncf,memref.dma_wait,llvm.intr.memcpy,spirv.CL.pow,llvm.intr.log,llvm.urem,spirv.GL.UMax,spirv.GL.SAbs,tensor.dim,llvm.intr.ctlz,arith.subi,llvm.sub,spirv.FOrdEqual,spirv.GL.InverseSqrt,omp.wsloop,llvm.intr.sqrt,llvm.fdiv,async.coro.suspend,arith.mulf,llvm.intr.ceil,tensor.insert,spirv.LogicalNot,vector.matrix_multiply,spirv.FOrdLessThan,spirv.Not,tensor.generate,vector.mask,async.add_to_group,llvm.intr.cos,linalg.copy,linalg.transpose,llvm.extractelement,spirv.IsInf,index.maxs,index.casts,bufferization.to_memref,async.runtime.create,builtin.unrealized_conversion_cast,scf.while,affine.if,linalg.index,llvm.xor,llvm.intr.vector.reduce.fadd,spirv.SNegate,affine.yield,arith.shli,arith.maxsi,spirv.GL.FClamp,vector.create_mask,memref.alloca_scope.return,llvm.frem,math.log1p,llvm.intr.cttz,llvm.intr.smax,omp.terminator,bufferization.clone,arith.maxui,math.rsqrt,vector.load,llvm.intr.vector.reduce.mul,spirv.SDiv,spirv.GL.RoundEven,spirv.CL.s_abs,spirv.CL.fmax,llvm.intr.assume,cf.br,llvm.mlir.zero,spirv.INotEqual,spirv.GL.FSign,vector.maskedload,memref.copy,index.shl,spirv.ISub,spirv.ULessThan,spirv.BitwiseOr,spirv.FUnordGreaterThanEqual,spirv.CL.s_max,shape.const_shape,arith.divf,memref.alloca,vector.outerproduct,llvm.intr.vector.reduce.xor,math.atan,spirv.CL.fmin,vector.reduction,index.constant,math.roundeven,spirv.BitwiseAnd,spirv.LogicalNotEqual,async.yield,index.sizeof,llvm.shufflevector,vector.warp_execute_on_lane_0,llvm.intr.umax,index.shru,async.coro.free,affine.apply,bufferization.alloc_tensor,llvm.shl,arith.select,async.runtime.resume,arith.floordivsi,math.exp,llvm.intr.powi,llvm.sext,vector.extract,spirv.FOrdLessThanEqual,index.floordivs,math.cos,index.divs,spirv.FUnordLessThan,tensor.expand_shape,linalg.matmul,vector.fma,async.create_group,llvm.intr.fmuladd,spirv.GL.Sinh,math.round,memref.load,llvm.trunc,async.coro.save,llvm.intr.masked.compressstore,scf.if,arith.cmpf,spirv.LogicalAnd,llvm.intr.ctpop,affine.vector_load,tensor.cast,llvm.intr.exp2,spirv.GL.Cosh,vector.transfer_write,llvm.store,index.ceildivs,llvm.inttoptr,spirv.CL.u_max,llvm.udiv,llvm.intr.smin,math.floor,index.castu,spirv.FNegate,vector.transfer_read,spirv.GL.Round,spirv.GL.Exp,spirv.FOrdNotEqual,arith.addi,memref.get_global,llvm.insertvalue,spirv.GL.FMix,llvm.intr.fabs,spirv.BitReverse,math.log2,spirv.SGreaterThanEqual,math.expm1,llvm.atomicrmw,arith.divsi,vector.bitcast,spirv.SGreaterThan,index.or,llvm.intr.stackrestore,spirv.UGreaterThan,memref.collapse_shape,spirv.UMod,pdl_interp.finalize,scf.for,spirv.GL.Floor,async.runtime.add_to_group,spirv.BitFieldSExtract,linalg.broadcast,spirv.GL.FMax,arith.minsi,llvm.call,spirv.BitFieldInsert,arith.extsi,spirv.CL.round,math.absi,scf.condition,async.runtime.set_available,memref.expand_shape,memref.realloc,vector.insertelement,llvm.intr.matrix.transpose,llvm.intr.exp,affine.max,spirv.CL.ceil,spirv.GL.SMax,llvm.fmul,arith.extui,arith.extf,pdl_interp.func,llvm.alloca,tensor.splat,index.bool.constant,affine.vector_store,spirv.GL.Pow,spirv.Constant,index.shrs,memref.assume_alignment,llvm.sdiv,memref.global,spirv.GL.Sqrt,index.and,memref.tensor_store,vector.extract_strided_slice,llvm.intr.abs,llvm.func,memref.atomic_rmw,scf.parallel,vector.extractelement,llvm.ptrtoint,vector.multi_reduction,spirv.FOrdGreaterThanEqual,omp.yield,math.copysign,llvm.fadd,scf.index_switch,vector.splat,llvm.fcmp,linalg.map,llvm.extractvalue,spirv.GL.Ldexp,async.await_all,spirv.LogicalEqual,llvm.intr.round,vector.shuffle,vector.insert,tensor.unpack,llvm.intr.floor,async.coro.begin,async.runtime.is_error,async.runtime.await,index.maxu,llvm.switch,spirv.GL.SClamp,omp.parallel,index.add,spirv.CL.rsqrt,llvm.fneg,spirv.IEqual,llvm.intr.vector.reduce.and,spirv.CL.tanh,vector.scatter,arith.shrui,llvm.intr.pow,affine.parallel,tensor.rank,spirv.CL.floor,arith.xori,arith.ceildivsi,llvm.ashr,llvm.cond_br,scf.yield,arith.muli,llvm.intr.copysign,llvm.srem,index.xor,func.return,tensor.yield,spirv.GL.Ceil,memref.extract_strided_metadata,math.tan,memref.dma_start,builtin.module,llvm.intr.masked.load,llvm.intr.vector.reduce.fmax,affine.for,spirv.GL.SSign,arith.remsi,llvm.intr.fma,llvm.and,arith.index_cast,llvm.mlir.constant,spirv.GL.Sin,llvm.add,spirv.GL.FMin,math.ceil,linalg.generic,vector.yield,scf.execute_region,scf.reduce.return,affine.store,llvm.intr.masked.gather,llvm.or,vector.compressstore,memref.dealloc,llvm.intr.log10,spirv.Return,affine.dma_wait,math.exp2,func.func,math.log,spirv.CL.sin,math.fma,vector.transpose,math.ctlz,llvm.intr.umin,math.ipowi,spirv.BitCount,llvm.intr.log2,spirv.FOrdGreaterThan,arith.divui,memref.cast,spirv.BitwiseXor,vector.scan,llvm.intr.matrix.multiply,tensor.from_elements,llvm.intr.stacksave,llvm.bitcast,spirv.GL.FAbs,math.atan2,math.sqrt,affine.load,llvm.icmp,spirv.ULessThanEqual,spirv.CL.fma,math.ctpop,vector.print,spirv.BitFieldUExtract,arith.minui,arith.cmpi,spirv.CL.fabs,math.cttz
all covered dialect: func,cf,vector,bufferization,llvm,spirv,omp,memref,linalg,affine,shape,index,async,arith,pdl_interp,math,builtin,tensor,scf
the number of operations: 415
the number of dialects: 19
