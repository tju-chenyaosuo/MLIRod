all covered operations: tensor.insert,linalg.transpose,llvm.or,cf.cond_br,spirv.GL.Sinh,llvm.intr.vector.reduce.add,memref.atomic_rmw,index.divu,index.ceildivu,memref.dma_start,linalg.yield,arith.addf,index.add,async.runtime.await,bufferization.to_memref,spirv.GL.Round,spirv.GL.FMin,math.sqrt,memref.alloca_scope,spirv.GL.Cos,spirv.CL.round,linalg.broadcast,index.shl,memref.dma_wait,vector.insert,scf.for,spirv.GL.Ceil,spirv.FUnordGreaterThan,spirv.UGreaterThan,func.func,affine.if,linalg.matmul,llvm.xor,spirv.SGreaterThanEqual,linalg.index,spirv.GL.Cosh,llvm.intr.cos,math.exp2,llvm.intr.abs,scf.yield,index.ceildivs,llvm.intr.floor,spirv.GL.Log,llvm.fneg,math.fpowi,llvm.intr.fabs,llvm.func,async.coro.save,func.return,arith.xori,llvm.cond_br,async.runtime.create_group,spirv.BitReverse,vector.compressstore,spirv.Constant,math.round,spirv.FOrdLessThanEqual,arith.muli,llvm.intr.smax,spirv.FOrdGreaterThanEqual,math.ceil,spirv.FUnordNotEqual,spirv.GL.FSign,memref.load,bufferization.clone,scf.parallel,memref.collapse_shape,math.ctlz,spirv.GL.UClamp,arith.andi,memref.expand_shape,tensor.splat,llvm.trunc,llvm.intr.vector.reduce.fadd,spirv.FOrdGreaterThan,llvm.intr.memcpy,arith.remui,llvm.intr.log2,vector.extract,spirv.CL.sin,spirv.CL.u_min,math.ctpop,llvm.intr.vector.reduce.and,llvm.intr.masked.load,math.absf,spirv.CL.s_abs,spirv.LogicalNot,llvm.shl,cf.assert,async.yield,llvm.store,llvm.intr.masked.compressstore,llvm.return,spirv.GL.Fma,spirv.GL.Exp,llvm.intr.ctpop,llvm.intr.assume,arith.cmpf,llvm.fcmp,math.log1p,scf.reduce,spirv.CL.ceil,llvm.intr.masked.gather,llvm.load,spirv.INotEqual,llvm.switch,scf.condition,vector.yield,spirv.CL.rsqrt,spirv.GL.SAbs,llvm.unreachable,spirv.CL.pow,llvm.intr.cttz,spirv.BitFieldUExtract,async.coro.end,spirv.GL.UMax,affine.parallel,spirv.IsInf,memref.global,affine.dma_wait,vector.splat,math.absi,cf.switch,math.atan,scf.execute_region,llvm.intr.sqrt,llvm.intr.fmuladd,llvm.br,llvm.extractvalue,arith.constant,bufferization.alloc_tensor,spirv.CL.exp,spirv.BitCount,llvm.extractelement,scf.while,spirv.GL.Acos,omp.terminator,spirv.CL.s_max,llvm.alloca,spirv.CL.fmin,llvm.ashr,async.runtime.set_available,math.exp,arith.remsi,vector.gather,spirv.IEqual,memref.assume_alignment,index.and,spirv.FNegate,memref.alloc,scf.if,scf.reduce.return,memref.dim,memref.get_global,index.maxs,arith.subi,memref.extract_strided_metadata,llvm.atomicrmw,llvm.ptrtoint,index.bool.constant,spirv.CL.erf,llvm.intr.vector.reduce.umin,llvm.lshr,llvm.intr.copysign,spirv.GL.Sqrt,spirv.GL.FClamp,arith.cmpi,arith.remf,arith.mulf,arith.shrsi,arith.floordivsi,bufferization.dealloc_tensor,llvm.mlir.global,async.coro.free,arith.extsi,spirv.FUnordGreaterThanEqual,index.xor,affine.store,vector.matrix_multiply,vector.multi_reduction,vector.store,memref.alloca,cf.br,vector.extract_strided_slice,llvm.intr.ctlz,spirv.CL.rint,spirv.GL.FAbs,llvm.intr.stackrestore,llvm.intr.smin,spirv.SGreaterThan,tensor.cast,math.cos,llvm.intr.log10,llvm.insertelement,spirv.IsNan,spirv.SLessThan,tensor.yield,linalg.dot,spirv.FOrdLessThan,spirv.GL.Floor,arith.index_cast,llvm.frem,memref.rank,arith.negf,memref.realloc,vector.constant_mask,spirv.CL.log,index.constant,llvm.udiv,spirv.CL.s_min,arith.divsi,async.await_all,tensor.collapse_shape,arith.divui,spirv.FUnordLessThan,llvm.intr.masked.scatter,spirv.GL.Asin,linalg.generic,tensor.unpack,math.log10,arith.divf,spirv.BitFieldInsert,index.mul,math.tanh,spirv.GL.InverseSqrt,linalg.copy,vector.load,arith.minsi,llvm.intr.umax,memref.dealloc,affine.dma_start,llvm.intr.roundeven,llvm.intr.vector.reduce.mul,arith.shli,vector.transfer_write,vector.maskedload,spirv.GL.SMin,vector.contract,llvm.sext,vector.insertelement,vector.flat_transpose,arith.ori,memref.tensor_store,math.log2,async.runtime.resume,llvm.sub,spirv.CL.u_max,affine.vector_store,math.fma,spirv.CL.floor,async.coro.id,bufferization.to_tensor,shape.const_shape,spirv.FUnordLessThanEqual,omp.wsloop,llvm.icmp,index.sizeof,func.call,spirv.FOrdEqual,llvm.insertvalue,spirv.CL.sqrt,llvm.urem,arith.maxsi,llvm.mlir.zero,llvm.intr.ceil,llvm.and,llvm.zext,vector.broadcast,vector.bitcast,affine.apply,llvm.intr.fma,spirv.Not,llvm.call,spirv.BitwiseOr,llvm.intr.pow,llvm.mlir.constant,math.rsqrt,vector.transpose,spirv.SLessThanEqual,index.casts,spirv.CL.fmax,spirv.GL.Tan,llvm.add,spirv.GL.SClamp,math.tan,affine.for,async.runtime.create,vector.outerproduct,math.log,affine.load,vector.reduction,llvm.mlir.addressof,llvm.inttoptr,math.roundeven,llvm.mlir.undef,memref.store,spirv.UGreaterThanEqual,spirv.LogicalNotEqual,affine.vector_load,shape.get_extent,builtin.module,vector.scatter,index.shru,llvm.intr.exp2,affine.max,spirv.BitFieldSExtract,index.divs,llvm.mul,vector.create_mask,arith.select,tensor.generate,async.create_group,vector.scan,math.atan2,shape.shape_of,index.floordivs,math.copysign,llvm.select,arith.ceildivsi,memref.cast,spirv.GL.Atan,linalg.map,async.coro.begin,llvm.sdiv,arith.shrui,spirv.LogicalEqual,tensor.expand_shape,spirv.CL.tanh,affine.min,llvm.srem,pdl_interp.func,math.ipowi,llvm.shufflevector,spirv.ULessThanEqual,llvm.intr.round,async.add_to_group,vector.print,llvm.intr.powi,vector.transfer_read,async.runtime.add_to_group,arith.extui,spirv.GL.Ldexp,llvm.fmul,llvm.fdiv,vector.warp_execute_on_lane_0,memref.copy,vector.mask,math.cttz,vector.fma,spirv.ULessThan,spirv.Unordered,vector.shuffle,spirv.GL.RoundEven,math.floor,spirv.FOrdNotEqual,llvm.intr.stacksave,spirv.GL.SMax,tensor.dim,llvm.intr.log,spirv.GL.FMix,spirv.GL.Tanh,omp.parallel,tensor.rank,arith.minui,spirv.LogicalOr,spirv.GL.Pow,math.expm1,index.shrs,vector.extractelement,async.runtime.is_error,async.coro.suspend,spirv.FUnordEqual,spirv.CL.fabs,llvm.intr.vector.reduce.smax,llvm.getelementptr,spirv.GL.Sin,tensor.extract,spirv.GL.SSign,llvm.intr.matrix.multiply,pdl_interp.finalize,arith.addi,spirv.LogicalAnd,spirv.CL.cos,omp.yield,spirv.GL.FMax,async.execute,tensor.empty,index.castu,index.or,index.sub,llvm.fadd,llvm.intr.umin,math.powf,spirv.CL.fma,memref.alloca_scope.return,builtin.unrealized_conversion_cast,llvm.bitcast,affine.yield,tensor.from_elements,llvm.intr.exp,index.maxu,scf.index_switch,spirv.BitwiseXor,llvm.fsub,spirv.BitwiseAnd,llvm.intr.matrix.transpose
all covered dialect: linalg,omp,pdl_interp,arith,scf,memref,tensor,func,vector,async,shape,bufferization,cf,spirv,index,affine,llvm,builtin,math
the number of operations: 406
the number of dialects: 19
